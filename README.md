# Simple Multilingual Retrieval Augmented Generation RAG System



# ЁЯУЪ Bangla-English RAG System (Offline, Ollama + FAISS)

A fully offline Retrieval-Augmented Generation (RAG) pipeline for answering **Bangla and English** queries using a PDF document (e.g., Bangla HSC Book). This system uses FAISS for vector search and **Ollama** (with Mistral) for answer generation.

---

## ЁЯФз Features

- ЁЯФН Query understanding in **Bangla and English**
- ЁЯУЦ PDF-to-Chunk pre-processing (sentence-level for accuracy)
- ЁЯМР Multilingual Embedding via `intfloat/multilingual-e5-base`
- ЁЯУж FAISS vector store for fast semantic retrieval
- ЁЯдЦ Local LLM support via **Ollama** (e.g., gemma:2b, LLaMA)
- ЁЯЫЬ Optional FastAPI server for API-based interaction

---

## ЁЯз░ Tools & Libraries

| Purpose        | Tool/Library                       |
|----------------|------------------------------------|
| Embedding      | `intfloat/multilingual-e5-base`    |
| LLM            | `Ollama` with `mistral` model      |
| Vector Search  | `FAISS`                            |
| PDF Parsing    | `PyMuPDF` (fitz)                   |
| API Server     | `FastAPI`, `Uvicorn`               |

---

## ЁЯУБ Project Structure

```

offline\_rag\_ollama/
тФЬтФАтФА data/                       тЖР Place your PDF file here
тФЬтФАтФА preprocess/
тФВ   тФФтФАтФА extract\_pdf\_pages.py   тЖР Extracts + chunks each page
тФЬтФАтФА embed\_and\_store.py         тЖР Embeds chunks into FAISS
тФЬтФАтФА rag\_pipeline.py            тЖР RAG query pipeline (terminal)
тФЬтФАтФА api/
тФВ   тФФтФАтФА main.py                тЖР FastAPI server
тФЬтФАтФА requirements.txt
тФФтФАтФА README.md

````

---

## ЁЯЪА Setup Instructions

### 1. Install [Ollama](https://ollama.com/download) and run your LLM:
```bash
ollama run mistral
````

### 2. Clone the repository

```bash
git clone https://github.com/your-username/offline_rag_ollama.git
cd offline_rag_ollama
```

### 3. Install Python dependencies

```bash
pip install -r requirements.txt
```

### 4. Put your Bangla Book PDF

Place your PDF file (e.g., `HSC26_Bangla_1st.pdf`) in the `data/` folder.

---

## тЪЩя╕П Running the Pipeline

### Step 1: Preprocess and Split PDF (into small sentence-based chunks)

```bash
python preprocess/extract_pdf_pages.py
```

### Step 2: Create FAISS Embeddings

```bash
python embed_and_store.py
```

### Step 3: Run RAG for a Question

```bash
python rag_pipeline.py
```

> Example input:

```text
ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?
```

---

## ЁЯМР Run the API Server

```bash
uvicorn api.main:app --reload
```

Then open:

```
http://localhost:8000/docs
```

---

## ЁЯзк Sample Test Questions

| Bangla Question                                 | Expected Answer |
| ----------------------------------------------- | --------------- |
| ржЕржирзБржкржорзЗрж░ ржнрж╛рж╖рж╛ржпрж╝ рж╕рзБржкрзБрж░рзБрж╖ ржХрж╛ржХрзЗ ржмрж▓рж╛ рж╣ржпрж╝рзЗржЫрзЗ?            | рж╢рзБржорзНржнрзБржирж╛рже       |
| ржХрж╛ржХрзЗ ржЕржирзБржкржорзЗрж░ ржнрж╛ржЧрзНржп ржжрзЗржмрждрж╛ ржмрж▓рзЗ ржЙрж▓рзНрж▓рзЗржЦ ржХрж░рж╛ рж╣ржпрж╝рзЗржЫрзЗ?    | ржорж╛ржорж╛ржХрзЗ          |
| ржмрж┐ржпрж╝рзЗрж░ рж╕ржоржпрж╝ ржХрж▓рзНржпрж╛ржгрзАрж░ ржкрзНрж░ржХрзГржд ржмржпрж╝рж╕ ржХржд ржЫрж┐рж▓?             | рззрзл ржмржЫрж░          |

---

## тЭУ FAQ

**Q: What chunking strategy is used?**
A: Sentence-based chunking (\~2-4 sentences per chunk) to maintain semantic focus in Bangla texts.

**Q: Which embedding model is used and why?**
A: `intfloat/multilingual-e5-base` тАФ provides accurate multilingual (Bangla+English) semantic representations.

**Q: How does it match a question to context?**
A: FAISS compares the E5 embedding of the query to precomputed chunk embeddings (cosine similarity).

**Q: What if the question is vague or lacks context?**
A: The system may return less relevant chunks. Future enhancement: query rewriting or context expansion.

---

---


